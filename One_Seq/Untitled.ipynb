{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda470d3-30b9-4bf1-ac2b-54a8a044f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "flst = glob.glob(\"DUF5413/PF17434_Split_*_putative_annotations.txt\")\n",
    "df_list = []\n",
    "for filename in sorted(flst):\n",
    "    df_list.append(pd.read_csv(filename))\n",
    "full_df = pd.concat(df_list)\n",
    "full_df.to_csv('DUF5413/PF17434_putative_annotations.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c71e5e-5350-47d1-85d5-6d1a634781ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# df = pd.read_csv(\"DUF5413/PF17434_putative_annotations.txt\")\n",
    "# split_df = np.array_split(df, 3)\n",
    "# b = [split_df[i].to_csv(f'DUF5413/PF17434_Split_{i}_putative_annotations.txt', index=False) for i in range(0, len(split_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f398b44-b6aa-45c8-a3e9-f3f4c3982b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PF4512'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dufID = \"DUF5454\"\n",
    "pfamID = \"PF4512_seqLen\"\n",
    "string = f\"../../fileUpload/{dufID}/{pfamID}.fasta\"\n",
    "dufANDpfam = string.split(\"/\")\n",
    "dufID = dufANDpfam[3]\n",
    "pfamID = dufANDpfam[4].replace('_seqLen', '').split(\".\")[0]\n",
    "pfamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d8db6f4-3b05-4d80-8529-655b989aab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264.0705971717834\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import time\n",
    "from Bio.Blast import NCBIWWW\n",
    "start = time.time()\n",
    "seqRecord = next(SeqIO.parse(open(\"/home/software/Test_DUF/Sequence_profile/DUF61/PF01886_consensus.fasta\"), \"fasta\"))\n",
    "result_handle = NCBIWWW.qblast(program=\"blastp\", database=\"nr\", sequence=seqRecord.seq, service=\"psi\", format_type=\"Tabular\")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1984e-03d0-4763-86a4-12e9c534cab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a76b66d1-efc0-4232-a2ea-a3c6865b0cb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m result_handle \u001b[38;5;241m=\u001b[39m NCBIWWW\u001b[38;5;241m.\u001b[39mqblast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblastp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnr\u001b[39m\u001b[38;5;124m\"\u001b[39m, seqRecord\u001b[38;5;241m.\u001b[39mseq, format_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtabular\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m blast_results \u001b[38;5;241m=\u001b[39m \u001b[43mresult_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Convert tabular results to DataFrame\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(pd\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mStringIO(blast_results), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", seqRecord.seq, format_type=\"tabular\")\n",
    "# blast_results = result_handle.read().decode()\n",
    "# df = pd.read_csv(pd.compat.StringIO(blast_results), sep=\"\\t\")\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7d2b503-060b-4d1b-80c3-80d2aa895445",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results = result_handle.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d982ea6d-9f48-4617-a831-18e1b4b8f31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<p><!--'],\n",
       " ['QBlastInfoBegin'],\n",
       " ['\\tStatus=READY'],\n",
       " ['QBlastInfoEnd'],\n",
       " ['--></p>'],\n",
       " ['<PRE>'],\n",
       " ['# blastp'],\n",
       " ['# Iteration: 0'],\n",
       " ['# Query: '],\n",
       " ['# RID: A5APAH76013'],\n",
       " ['# Database: nr'],\n",
       " ['# Fields: query acc.ver',\n",
       "  ' subject acc.ver',\n",
       "  ' % identity',\n",
       "  ' alignment length',\n",
       "  ' mismatches',\n",
       "  ' gap opens',\n",
       "  ' q. start',\n",
       "  ' q. end',\n",
       "  ' s. start',\n",
       "  ' s. end',\n",
       "  ' evalue',\n",
       "  ' bit score',\n",
       "  ' % positives'],\n",
       " ['# 50 hits found'],\n",
       " ['Query_75377\\tKXA90688.1\\t48.227\\t141\\t60\\t3\\t22\\t162\\t4\\t131\\t3.67e-17\\t84.7\\t58.87'],\n",
       " ['Query_75377\\tKXA92376.1\\t45.714\\t140\\t65\\t3\\t23\\t162\\t5\\t133\\t1.62e-14\\t78.2\\t56.43'],\n",
       " ['Query_75377\\tKXA89148.1\\t43.262\\t141\\t69\\t3\\t22\\t162\\t4\\t133\\t1.15e-13\\t75.9\\t57.45'],\n",
       " ['Query_75377\\tTET00217.1\\t41.007\\t139\\t69\\t3\\t22\\t160\\t4\\t129\\t1.18e-13\\t75.5\\t51.80'],\n",
       " ['Query_75377\\tMDF2956743.1\\t42.446\\t139\\t68\\t3\\t22\\t160\\t5\\t131\\t2.08e-13\\t74.7\\t51.08'],\n",
       " ['Query_75377\\tTES83875.1\\t41.007\\t139\\t69\\t3\\t22\\t160\\t4\\t129\\t2.21e-13\\t74.7\\t52.52'],\n",
       " ['Query_75377\\tKUO41632.1\\t41.007\\t139\\t69\\t3\\t22\\t160\\t4\\t129\\t2.26e-13\\t74.7\\t52.52'],\n",
       " ['Query_75377\\tMQY68536.1\\t40.288\\t139\\t70\\t3\\t22\\t160\\t9\\t134\\t2.27e-13\\t74.7\\t51.08'],\n",
       " ['Query_75377\\tHDO64238.1\\t41.727\\t139\\t69\\t3\\t22\\t160\\t5\\t131\\t2.63e-13\\t74.7\\t51.08'],\n",
       " ['Query_75377\\tRJS73200.1\\t35.461\\t141\\t79\\t3\\t22\\t162\\t4\\t132\\t4.08e-13\\t73.9\\t55.32'],\n",
       " ['Query_75377\\tMCK4405328.1\\t41.007\\t139\\t69\\t3\\t22\\t160\\t4\\t129\\t4.47e-13\\t73.9\\t51.08'],\n",
       " ['Query_75377\\tOFV66370.1\\t34.752\\t141\\t80\\t3\\t22\\t162\\t4\\t132\\t5.79e-13\\t73.6\\t55.32'],\n",
       " ['Query_75377\\tKUO40323.1\\t41.727\\t139\\t68\\t3\\t22\\t160\\t4\\t129\\t9.73e-13\\t73.2\\t52.52'],\n",
       " ['Query_75377\\tWP_013826486.1\\t39.716\\t141\\t70\\t3\\t22\\t162\\t9\\t134\\t1.35e-12\\t72.8\\t53.19'],\n",
       " ['Query_75377\\tKXB07895.1\\t41.844\\t141\\t71\\t3\\t22\\t162\\t4\\t133\\t1.86e-12\\t72.4\\t56.03'],\n",
       " ['Query_75377\\tRLG58492.1\\t41.304\\t138\\t70\\t3\\t23\\t160\\t7\\t133\\t2.39e-12\\t72.0\\t55.07'],\n",
       " ['Query_75377\\tKXB02168.1\\t43.972\\t141\\t67\\t3\\t22\\t162\\t4\\t132\\t2.42e-12\\t72.0\\t55.32'],\n",
       " ['Query_75377\\tOPX78407.1\\t38.849\\t139\\t73\\t3\\t22\\t160\\t16\\t142\\t2.84e-12\\t72.4\\t51.80'],\n",
       " ['Query_75377\\tKUO41660.1\\t38.129\\t139\\t73\\t3\\t22\\t160\\t4\\t129\\t3.32e-12\\t71.6\\t51.80'],\n",
       " ['Query_75377\\tAGF93551.1\\t43.262\\t141\\t68\\t3\\t22\\t162\\t4\\t132\\t3.61e-12\\t71.6\\t55.32'],\n",
       " ['Query_75377\\tWP_074359254.1\\t39.007\\t141\\t71\\t3\\t22\\t162\\t7\\t132\\t4.09e-12\\t71.6\\t49.65'],\n",
       " ['Query_75377\\tMCS4542084.1\\t41.429\\t140\\t70\\t3\\t23\\t162\\t11\\t138\\t5.92e-12\\t71.2\\t52.86'],\n",
       " ['Query_75377\\tWP_283169533.1\\t39.007\\t141\\t71\\t3\\t22\\t162\\t7\\t132\\t7.33e-12\\t70.9\\t49.65'],\n",
       " ['Query_75377\\tNPB01747.1\\t36.879\\t141\\t76\\t3\\t22\\t162\\t8\\t135\\t1.47e-11\\t70.5\\t50.35'],\n",
       " ['Query_75377\\tNOZ58261.1\\t39.855\\t138\\t71\\t3\\t23\\t160\\t7\\t132\\t1.55e-11\\t70.1\\t52.90'],\n",
       " ['Query_75377\\tMDF2956112.1\\t38.849\\t139\\t73\\t3\\t22\\t160\\t3\\t129\\t2.25e-11\\t69.3\\t49.64'],\n",
       " ['Query_75377\\tVVB91399.1\\t37.681\\t138\\t76\\t3\\t23\\t160\\t10\\t137\\t2.37e-11\\t69.7\\t50.00'],\n",
       " ['Query_75377\\tRCV64183.1\\t37.410\\t139\\t75\\t3\\t22\\t160\\t6\\t132\\t3.36e-11\\t69.3\\t51.08'],\n",
       " ['Query_75377\\tMCE5214975.1\\t36.170\\t141\\t75\\t3\\t22\\t162\\t9\\t134\\t3.71e-11\\t68.9\\t51.77'],\n",
       " ['Query_75377\\tMDD3753968.1\\t36.170\\t141\\t75\\t3\\t22\\t162\\t9\\t134\\t4.69e-11\\t68.6\\t53.19'],\n",
       " ['Query_75377\\tOPX60784.1\\t39.007\\t141\\t71\\t3\\t22\\t162\\t9\\t134\\t5.44e-11\\t68.6\\t52.48'],\n",
       " ['Query_75377\\tMCW7076145.1\\t32.374\\t139\\t82\\t3\\t22\\t160\\t4\\t130\\t1.07e-10\\t67.8\\t53.96'],\n",
       " ['Query_75377\\tTMS43269.1\\t39.007\\t141\\t71\\t3\\t22\\t162\\t9\\t134\\t1.10e-10\\t67.8\\t53.19'],\n",
       " ['Query_75377\\tMDD1774483.1\\t38.298\\t141\\t72\\t3\\t22\\t162\\t9\\t134\\t1.12e-10\\t67.8\\t51.77'],\n",
       " ['Query_75377\\tMCX9089068.1\\t37.681\\t138\\t79\\t3\\t23\\t160\\t10\\t140\\t1.23e-10\\t67.8\\t52.17'],\n",
       " ['Query_75377\\tMCW3129756.1\\t36.879\\t141\\t80\\t3\\t22\\t162\\t32\\t163\\t1.38e-10\\t68.2\\t51.06'],\n",
       " ['Query_75377\\tMBK5191033.1\\t36.620\\t142\\t83\\t3\\t22\\t160\\t8\\t145\\t1.40e-10\\t67.8\\t50.70'],\n",
       " ['Query_75377\\tWP_010876580.1\\t37.589\\t141\\t73\\t3\\t22\\t162\\t7\\t132\\t1.62e-10\\t67.4\\t49.65'],\n",
       " ['Query_75377\\tMBC7111191.1\\t37.589\\t141\\t73\\t3\\t22\\t162\\t7\\t132\\t1.80e-10\\t67.0\\t49.65'],\n",
       " ['Query_75377\\tWP_071907519.1\\t37.589\\t141\\t73\\t3\\t22\\t162\\t8\\t133\\t1.95e-10\\t67.0\\t51.06'],\n",
       " ['Query_75377\\tKXB07941.1\\t40.426\\t141\\t73\\t3\\t22\\t162\\t3\\t132\\t1.97e-10\\t67.4\\t49.65'],\n",
       " ['Query_75377\\tWP_209625688.1\\t39.007\\t141\\t71\\t3\\t22\\t162\\t9\\t134\\t2.57e-10\\t66.6\\t52.48'],\n",
       " ['Query_75377\\tHHT19072.1\\t35.461\\t141\\t76\\t3\\t22\\t162\\t9\\t134\\t2.69e-10\\t66.6\\t53.19'],\n",
       " ['Query_75377\\tHID60632.1\\t38.129\\t139\\t72\\t3\\t22\\t160\\t2\\t126\\t2.74e-10\\t66.6\\t48.92'],\n",
       " ['Query_75377\\tWP_013644045.1\\t40.426\\t141\\t69\\t3\\t22\\t162\\t9\\t134\\t3.18e-10\\t66.6\\t51.77'],\n",
       " ['Query_75377\\tMBU2559392.1\\t37.143\\t140\\t76\\t3\\t23\\t162\\t7\\t134\\t3.40e-10\\t66.6\\t48.57'],\n",
       " ['Query_75377\\tUTB33556.1\\t39.716\\t141\\t70\\t3\\t22\\t162\\t9\\t134\\t3.42e-10\\t66.6\\t51.06'],\n",
       " ['Query_75377\\tWP_217993110.1\\t36.496\\t137\\t80\\t3\\t24\\t160\\t11\\t140\\t3.56e-10\\t66.6\\t51.09'],\n",
       " ['Query_75377\\tWP_096203949.1\\t38.406\\t138\\t75\\t3\\t23\\t160\\t10\\t137\\t3.71e-10\\t66.6\\t50.00'],\n",
       " ['Query_75377\\tKAB2942193.1\\t36.496\\t137\\t80\\t3\\t24\\t160\\t2\\t131\\t4.22e-10\\t66.2\\t51.09'],\n",
       " ['</PRE>'],\n",
       " [''],\n",
       " ['']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = list(map(lambda x: x.split(','),blast_results.split(\"\\n\")))\n",
    "# df = pd.read_csv(blast_results, sep=\"\\t\", header=None)\n",
    "# df.columns = [\"Query ID\", \"Subject ID\", \"Identity\", \"Alignment Length\", \"Mismatches\", \"Gaps\", \n",
    "#               \"Query Start\", \"Query End\", \"Subject Start\", \"Subject End\", \"E-value\", \"Bit Score\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe19aef-1b0f-48b6-9aa1-c4492f67a44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import time\n",
    "from Bio.Blast import NCBIWWW\n",
    "start = time.time()\n",
    "seqRecord = next(SeqIO.parse(open(\"/home/software/Test_DUF/Sequence_profile/DUF61/PF01886_consensus.fasta\"), \"fasta\"))\n",
    "result_handle = NCBIWWW.qblast(program=\"blastp\", database=\"nr\", sequence=seqRecord.seq, service=\"psi\", format_type=\"Tabular\")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "62620aba-8e21-463f-9dae-8b573b0c9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import time\n",
    "from Bio.Blast import NCBIWWW\n",
    "from bs4 import BeautifulSoup as bs\n",
    "seq_record = next(SeqIO.parse(open('DUF1325/PF07039_consensus.fasta'),'fasta')) \n",
    "result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", seq_record.seq, format_type=\"HTML\", hitlist_size=500, service =\"psi\")\n",
    "result = result_handle.read()\n",
    "soup = bs(result, 'html.parser')\n",
    "table = soup.find(\"table\", {\"id\": \"dscTable\"}).find(\"tbody\").findAll(\"tr\")\n",
    "df = pd.DataFrame(columns=[\"desc\", \"queryCover\", \"percentIden\", \"seqLen\", \"acclen\"])\n",
    "for row in table:\n",
    "    desc = row.findAll(\"td\")[1].find(\"a\").text\n",
    "    slen = row.findAll(\"td\")[1].find(\"a\")[\"len\"]\n",
    "    qCov = row.findAll(\"td\")[7].text.rstrip(\"%\")\n",
    "    piden = row.findAll(\"td\")[9].text.rstrip(\"%\")\n",
    "    acclen = row.findAll(\"td\")[10].text\n",
    "    df.loc[len(df.index)] = [desc, qCov, piden, slen, acclen]\n",
    "df.to_csv(\"DUF1325/PF07039_psiblast.out\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "648bd8b9-61dd-433d-8615-ac70891b1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Function to count total occurrences of word in entire file\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def word_count(input_word, word_dict):\n",
    "    for words in input_word:\n",
    "        if words != '':\n",
    "            if words.lower() in word_dict:\n",
    "                word_dict[words.lower()] += 1\n",
    "            else:\n",
    "                word_dict[words.lower()] = 1\n",
    "\n",
    "# psiblast_output_file = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_psiblast.out\"\n",
    "# allTitlesFile = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_all_titles.txt\"\n",
    "# wordDictFile = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_word_dict.txt\"\n",
    "# delListFile = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_del_list.txt\"\n",
    "# if c == 0:\n",
    "\n",
    "# def psiblast_out_process(dufID, pfamID, c):\n",
    "dufID = \"361\"\n",
    "pfamID = \"Seq_1\"\n",
    "psiblast_output_file = f\"{dufID}/{pfamID}_psiblast.out\"\n",
    "allTitlesFile = f\"{dufID}/{pfamID}_all_titles.txt\"\n",
    "wordDictFile = f\"{dufID}/{pfamID}_word_dict.txt\"\n",
    "delListFile = f\"{dufID}/{pfamID}_del_list.txt\"\n",
    "\n",
    "\n",
    "# deleting empty lines, if any in the psiblast output file\n",
    "cmd = f\"sed -i '/^$/d' {psiblast_output_file}\"\n",
    "os.system(cmd)\n",
    "\n",
    "# counting number of lines in psiblast output....to check if no hits obtained (empty file)\n",
    "blast_cnt = os.popen(f\"wc -l < {psiblast_output_file}\").read()\n",
    "\n",
    "if int(blast_cnt.rstrip()) > 1:\n",
    "    lastLine = f\"sed '${{/Search has CONVERGED!/d;}}' {psiblast_output_file} > temFile.txt && mv temFile.txt {psiblast_output_file}\"\n",
    "    os.system(lastLine)\n",
    "    psibRst = pd.read_csv(psiblast_output_file, header=None)\n",
    "    try:\n",
    "        titles = open(allTitlesFile, 'w')           \n",
    "        for i in range(1, len(psibRst)):\n",
    "            if float(psibRst[1][i]) >= 80 and float(psibRst[2][i]) >= 20:\n",
    "                target_cov = float(psibRst[3][i]) / float(psibRst[4][i]) * 100\n",
    "                if 80 <= target_cov <= 120:\n",
    "                    # x = [item.rstrip().split(sep=\"[\")[0].strip() for item in y]\n",
    "                    x = psibRst[0][i].split(sep=\"[\")[0].strip()\n",
    "                    titles.write(x+\"\\n\")\n",
    "        titles.close()\n",
    "    except Exception as e:\n",
    "        status = \"Error while retrieving hits titles\"\n",
    "\n",
    "    # print(\"**Creating word dictionary**\")\n",
    "    file_path = allTitlesFile\n",
    "\n",
    "    # Creating word dictionary\n",
    "    word_dict = collections.OrderedDict()\n",
    "\n",
    "    filter_word_list = []\n",
    "    del_list = [dufID, pfamID]\n",
    "\n",
    "    chars = ['(', ')', ':', '=', ',', \"'\", ';']\n",
    "\n",
    "    # deleting unwanted characters from titles file\n",
    "    for i in chars:\n",
    "        cmd = f'sed -i \"s/{i}//gI\" {allTitlesFile}'\n",
    "        os.system(cmd)\n",
    "\n",
    "    # store count of words\n",
    "    with open(file_path) as hits:\n",
    "        for line in hits:\n",
    "            word_count(line.strip().split(' '), word_dict)\n",
    "\n",
    "    word_list = list(word_dict.items())\n",
    "\n",
    "    # list of common words to be eliminated during filtration for putative hits\n",
    "    common_word_list = ['DUF', 'domain-containing', 'uncharacterized', 'uncharacterised', 'multispecies',\n",
    "                        'wiith', 'to', 'of', 'in', 'similar', 'from', 'plasmid', '(plasmid)', 'contains',\n",
    "                        'containing', 'partial', 'unknown', 'unnamed', 'hypothetical','RecName FullUncharacterized',\n",
    "                        'RecName Full Uncharacterize', 'PREDICTED', 'LOW QUALITY PROTEIN']\n",
    "\n",
    "    # filtering word list based eliminating low occurrences\n",
    "    for i in word_list:\n",
    "        occ = os.popen(f'grep -i -c \"{i[0]}\" {allTitlesFile}').read()\n",
    "        if occ != '' and int(occ) > 5:\n",
    "            filter_word_list += [i]\n",
    "        else:\n",
    "            del_list = del_list + [i[0]]\n",
    "\n",
    "    # filtering word list by eliminating words in common word list\n",
    "    for x in common_word_list:\n",
    "        filter_word_list = [i for i in filter_word_list if not i[0].lower().startswith(x.lower())]\n",
    "        del_list = del_list + [x]\n",
    "\n",
    "    # filtering word list by eliminating words which are combination of letters and numbers\n",
    "\n",
    "    filter_word_list = [i for i in filter_word_list if\n",
    "                        not re.search(r'\\d', i[0]) is not None and re.search(r'[a-zA-Z]', i[0]) is not None]\n",
    "    del_list = del_list + [i[0] for i in filter_word_list if\n",
    "                           re.search(r'\\d', i[0]) is not None and re.search(r'[a-zA-Z]', i[0]) is not None]\n",
    "\n",
    "    # writing filtered word dict to file:\n",
    "    with open(wordDictFile, \"w\") as f:\n",
    "        for kv in filter_word_list:\n",
    "            f.write(str(kv) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "    # writing deleted words to file:\n",
    "    with open(delListFile, \"w\") as f:\n",
    "        for word in del_list:\n",
    "            f.write(str(word) + '\\n')\n",
    "    f.close()\n",
    "        \n",
    "# psiblastOutputFile = sys.argv[1]\n",
    "# psiblast_out_process(psiblastOutputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "25ef8aae-b9d6-4a6e-abd8-ac1584bba331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saga-Associated Factor 29'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = \"Saga-Associated Factor 29 [Manis pentadactyla]\"\n",
    "y.split(sep=\"[\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e6b62c19-56cb-4b15-9992-9e169db5c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", seq_record.seq, service=\"psi\")\n",
    "\n",
    "# # Parse the result\n",
    "# blast_records = NCBIXML.parse(result_handle)\n",
    "\n",
    "# # Extract the length of each sequence\n",
    "# sequence_lengths = []\n",
    "# for record in blast_records:\n",
    "#     for alignment in record.alignments:\n",
    "#         for hsp in alignment.hsps:\n",
    "#             sequence_length = len(hsp.sbjct)\n",
    "#             sequence_lengths.append(sequence_length)\n",
    "\n",
    "# # Print the sequence lengths\n",
    "# for length in sequence_lengths:\n",
    "#     print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e9abecea-75e2-4226-886c-4a71e10937a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7edcc5d7-9c90-4ba8-b141-96038ee87743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc61f3-27d3-4ab4-a296-d8410fc3751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# form_data = {}\n",
    "# searchText = \"D40N\"\n",
    "# url = \"http://bts.ibab.ac.in/autoResult.php?kwMutF=L36R&selModel=GALNS\"\n",
    "# proxies = {'https':'http://proxy.ibab.ac.in:3128/', 'http':'http://proxy.ibab.ac.in:3128/'}\n",
    "# response = requests.get(url)\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# # print(soup.find(\"table\", {\"id\": \"prdtRst\"}))\n",
    "# if soup.find(\"table\", {\"id\": \"prdtRst\"}) is None:\n",
    "#     print(\"Yes nothing is there\")\n",
    "# else:\n",
    "#     print(\"Table is there\")\n",
    "# # table = soup.find(\"table\", {\"id\": \"prdtRst\"}).select(\"tr\")[1].select(\"td\")[1].text\n",
    "# # print(table.select(\"tr\")[1].select(\"td\")[1].text)\n",
    "# # rows = table.findAll('tr')\n",
    "# # rows[1]\n",
    "# # print(table)\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(columns=[\"Mutation\", \"MetaPredictor\"])\n",
    "# Mut = pd.read_csv(\"known_mutation_prediction_with_other_tools/P34059/mutations_test.txt\", header=None)\n",
    "# proxies = {'https':'http://proxy.ibab.ac.in:3128/', 'http':'http://proxy.ibab.ac.in:3128/'}\n",
    "# for i in Mut[0]:\n",
    "#     url = f\"http://bts.ibab.ac.in/autoResult.php?kwMutF={i}&selModel=GALNS\"\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#     table = soup.find(\"table\", {\"id\": \"prdtRst\"})\n",
    "#     if table is None:\n",
    "#         df.loc[len(df.index)] = [i, \"Severe\"]\n",
    "#     else:\n",
    "#         mutPrediction = table.select(\"tr\")[1].select(\"td\")[1].text\n",
    "#         df.loc[len(df.index)] = [i, mutPrediction]\n",
    "# df.to_csv(\"known_Mutation_Prediction_of_MPS_IVA.csv\", index=False)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce440f6-a529-486e-8813-5011765ef25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5d7e2522-2985-4104-bdbb-658893595092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function qblast in module Bio.Blast.NCBIWWW:\n",
      "\n",
      "qblast(program, database, sequence, url_base='https://blast.ncbi.nlm.nih.gov/Blast.cgi', auto_format=None, composition_based_statistics=None, db_genetic_code=None, endpoints=None, entrez_query='(none)', expect=10.0, filter=None, gapcosts=None, genetic_code=None, hitlist_size=50, i_thresh=None, layout=None, lcase_mask=None, matrix_name=None, nucl_penalty=None, nucl_reward=None, other_advanced=None, perc_ident=None, phi_pattern=None, query_file=None, query_believe_defline=None, query_from=None, query_to=None, searchsp_eff=None, service=None, threshold=None, ungapped_alignment=None, word_size=None, short_query=None, alignments=500, alignment_view=None, descriptions=500, entrez_links_new_window=None, expect_low=None, expect_high=None, format_entrez_query=None, format_object=None, format_type='XML', ncbi_gi=None, results_file=None, show_overview=None, megablast=None, template_type=None, template_length=None)\n",
      "    BLAST search using NCBI's QBLAST server or a cloud service provider.\n",
      "    \n",
      "    Supports all parameters of the old qblast API for Put and Get.\n",
      "    \n",
      "    Please note that NCBI uses the new Common URL API for BLAST searches\n",
      "    on the internet (http://ncbi.github.io/blast-cloud/dev/api.html). Thus,\n",
      "    some of the parameters used by this function are not (or are no longer)\n",
      "    officially supported by NCBI. Although they are still functioning, this\n",
      "    may change in the future.\n",
      "    \n",
      "    The Common URL API (http://ncbi.github.io/blast-cloud/dev/api.html) allows\n",
      "    doing BLAST searches on cloud servers. To use this feature, please set\n",
      "    ``url_base='http://host.my.cloud.service.provider.com/cgi-bin/blast.cgi'``\n",
      "    and ``format_object='Alignment'``. For more details, please see\n",
      "    https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=CloudBlast\n",
      "    \n",
      "    Some useful parameters:\n",
      "    \n",
      "     - program        blastn, blastp, blastx, tblastn, or tblastx (lower case)\n",
      "     - database       Which database to search against (e.g. \"nr\").\n",
      "     - sequence       The sequence to search.\n",
      "     - ncbi_gi        TRUE/FALSE whether to give 'gi' identifier.\n",
      "     - descriptions   Number of descriptions to show.  Def 500.\n",
      "     - alignments     Number of alignments to show.  Def 500.\n",
      "     - expect         An expect value cutoff.  Def 10.0.\n",
      "     - matrix_name    Specify an alt. matrix (PAM30, PAM70, BLOSUM80, BLOSUM45).\n",
      "     - filter         \"none\" turns off filtering.  Default no filtering\n",
      "     - format_type    \"HTML\", \"Text\", \"ASN.1\", or \"XML\".  Def. \"XML\".\n",
      "     - entrez_query   Entrez query to limit Blast search\n",
      "     - hitlist_size   Number of hits to return. Default 50\n",
      "     - megablast      TRUE/FALSE whether to use MEga BLAST algorithm (blastn only)\n",
      "     - short_query    TRUE/FALSE whether to adjust the search parameters for a\n",
      "                      short query sequence. Note that this will override\n",
      "                      manually set parameters like word size and e value. Turns\n",
      "                      off when sequence length is > 30 residues. Default: None.\n",
      "     - service        plain, psi, phi, rpsblast, megablast (lower case)\n",
      "    \n",
      "    This function does no checking of the validity of the parameters\n",
      "    and passes the values to the server as is.  More help is available at:\n",
      "    https://ncbi.github.io/blast-cloud/dev/api.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NCBIWWW.qblast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "34409bc2-2bbf-44ef-b0a4-5e74b9aba84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSI-BLAST of consensus sequence against nr database with required parameters\n",
    "# qcovs -> query coverage; pident -> percentage identity; length -> alignment length; slen -> target/reference seq length\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# def psiblast(dufID, pfamID, c):\n",
    "#     if int(c) == 0:\n",
    "#         location = \"/var/www/html/\"\n",
    "#         inputFile = f\"{location}fileUpload/{dufID}/{pfamID}.fasta\"\n",
    "#         outputFile = f\"{location}fileUpload/{dufID}/{pfamID}_psiblast.out\"\n",
    "#     else: \n",
    "#         inputFile = f\"fileUpload/{dufID}/{pfamID}_Split_{c}.fasta\"\n",
    "#         outputFile = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_psiblast.out\"\n",
    "#     try:\n",
    "#         cmd_psiblast = f'psiblast -query {inputFile} -db /home/user/disk/proteinDB/nr -outfmt \"6 qseqid saccver qcovs pident length slen salltitles mismatch gapopen qstart qend sstart send evalue bitscore\" -out {outputFile} -out_pssm fileUpload/{dufID}/{pfamID}.pssm -save_each_pssm -num_threads 8'\n",
    "        \n",
    "#         os.system(cmd_psiblast)\n",
    "#         status = \"psiblast completed\"\n",
    "\n",
    "#     except:\n",
    "#         status = \"Error during psiblast run\"\n",
    "\n",
    "#     # return inputFile, outputFile\n",
    "\n",
    "# consSeqFile = sys.argv[1]\n",
    "# pfID = sys.argv[2]\n",
    "# count = sys.argv[3]\n",
    "# psiblast(consSeqFile, pfID, count)\n",
    "# # psiblast(\"PF20532_consensus.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6c6dd434-f3ba-493c-90d4-3508a5805ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_handle = NCBIWWW.qblast('tblastn', 'tsa_nt', query, format_type=\"Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a2e50a6d-3694-410b-bdd4-0747ddfa6b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/www/html/annoduf_Script/One_Seq'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "d46609d5-6a59-43a5-a219-b298d78ff148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "dufID = 751\n",
    "pfamID = \"Seq_1\"\n",
    "\n",
    "locate = f\"/var/www/html/fileUpload/{dufID}/{pfamID}\"\n",
    "input_file = f\"{locate}.fasta\"\n",
    "c = 1\n",
    "aligned_fragments = []\n",
    "previousValue = None\n",
    "\n",
    "def writeSeq():\n",
    "    my_seqs = SeqRecord(Seq(fragment_seq), id=fragment_id, name=record.name, description=record.description)\n",
    "    SeqIO.write(my_seqs, f\"{locate}_Split_{c}.fasta\", \"fasta\")\n",
    "    \n",
    "with open(input_file) as input_handle:\n",
    "    records = list(SeqIO.parse(input_handle, \"fasta\"))\n",
    "    for record in records:\n",
    "        for i in range(0, len(record.seq), 250):\n",
    "            fragment_seq = record.seq[i:i+500]\n",
    "            fragment_id = f\"{record.id}_{i+1}-{i+len(fragment_seq)}\"\n",
    "            if previousValue is not None:\n",
    "                if previousValue != i+len(fragment_seq):\n",
    "                    writeSeq()\n",
    "                    c += 1\n",
    "            else:\n",
    "                writeSeq()\n",
    "                c += 1\n",
    "            previousValue = i+len(fragment_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939b9bf-7394-4386-a7f4-f586f963b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Define a function that represents the task you want to perform in the loop\n",
    "def task(index):\n",
    "    print(f\"Thread {threading.current_thread().name}: Executing task {index}\")\n",
    "\n",
    "# Number of threads you want to use\n",
    "num_threads = 5\n",
    "\n",
    "# Number of iterations in the loop\n",
    "num_iterations = 10\n",
    "\n",
    "# Create a list to store the thread objects\n",
    "threads = []\n",
    "\n",
    "# Loop to create and start the threads\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=task, args=(i,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"All threads have finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04369938-70da-43fe-9e01-dd0917f9383d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "fafddb7b-afab-444a-9362-140b7f7771ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast import NCBIWWW\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def psiblast(dufID, pfamID, c):\n",
    "    print(dufID, pfamID, c)\n",
    "    if int(c) == 0:\n",
    "        inputFile = f\"../../fileUpload/{dufID}/{pfamID}.fasta\"\n",
    "        outputFile = f\"../../fileUpload/{dufID}/{pfamID}_psiblast.out\"\n",
    "    else: \n",
    "        inputFile = f\"../../fileUpload/{dufID}/{pfamID}_Split_{c}.fasta\"\n",
    "        outputFile = f\"../../fileUpload/{dufID}/{pfamID}_Split_{c}_psiblast.out\"\n",
    "        \n",
    "    # dufANDpfam = consensus_seq_file.split(\"/\")\n",
    "    # dufID = dufANDpfam[1]\n",
    "    # pfamID = dufANDpfam[2].replace('_consensus', '').split(\".\")[0]\n",
    "    seq_record = next(SeqIO.parse(open(inputFile),'fasta')) \n",
    "    result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", seq_record.seq, format_type=\"HTML\", hitlist_size=500, service =\"psi\")\n",
    "    result = result_handle.read()\n",
    "    soup = bs(result, 'html.parser')\n",
    "    table = soup.find(\"table\", {\"id\": \"dscTable\"}).find(\"tbody\").findAll(\"tr\")\n",
    "    df = pd.DataFrame(columns=[\"desc\", \"queryCover\", \"percentIden\", \"seqLen\", \"acclen\"])\n",
    "    for row in table:\n",
    "        desc = row.findAll(\"td\")[1].find(\"a\").text\n",
    "        slen = row.findAll(\"td\")[1].find(\"a\")[\"len\"]\n",
    "        qCov = row.findAll(\"td\")[7].text.rstrip(\"%\")\n",
    "        piden = row.findAll(\"td\")[9].text.rstrip(\"%\")\n",
    "        acclen = row.findAll(\"td\")[10].text\n",
    "        df.loc[len(df.index)] = [desc, qCov, piden, slen, acclen]\n",
    "    df.to_csv(outputFile, index=False)\n",
    "    \n",
    "import time\n",
    "print('** PSI-BLAST in progress.... **')\n",
    "start_time = time.time()\n",
    "psiblast(751, \"Seq_1\", 0)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print('** PSI-BLAST process completed in {:.2f} minutes {:.2f} seconds **'.format(execution_time // 60, execution_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "6829cf91-f818-4473-9806-f389de76788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** PSI-BLAST in progress.... **\n",
      "751 Seq_1 0\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error Tunnel connection failed: 503 Service Unavailable>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:1354\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1354\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1256\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1302\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1301\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1251\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1251\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1011\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1011\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1014\u001b[0m \n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:951\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1418\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1418\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:927\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m--> 927\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:905\u001b[0m, in \u001b[0;36mHTTPConnection._tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTunnel connection failed: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (code,\n\u001b[1;32m    906\u001b[0m                                                        message\u001b[38;5;241m.\u001b[39mstrip()))\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: Tunnel connection failed: 503 Service Unavailable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [411]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m** PSI-BLAST in progress.... **\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpsiblast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m751\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSeq_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Input \u001b[0;32mIn [409]\u001b[0m, in \u001b[0;36mpsiblast\u001b[0;34m(dufID, pfamID, c)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# dufANDpfam = consensus_seq_file.split(\"/\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# dufID = dufANDpfam[1]\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# pfamID = dufANDpfam[2].replace('_consensus', '').split(\".\")[0]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m seq_record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(SeqIO\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;28mopen\u001b[39m(inputFile),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfasta\u001b[39m\u001b[38;5;124m'\u001b[39m)) \n\u001b[0;32m---> 22\u001b[0m result_handle \u001b[38;5;241m=\u001b[39m \u001b[43mNCBIWWW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqblast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblastp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_record\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHTML\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhitlist_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpsi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m result \u001b[38;5;241m=\u001b[39m result_handle\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     24\u001b[0m soup \u001b[38;5;241m=\u001b[39m bs(result, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/Bio/Blast/NCBIWWW.py:256\u001b[0m, in \u001b[0;36mqblast\u001b[0;34m(program, database, sequence, url_base, auto_format, composition_based_statistics, db_genetic_code, endpoints, entrez_query, expect, filter, gapcosts, genetic_code, hitlist_size, i_thresh, layout, lcase_mask, matrix_name, nucl_penalty, nucl_reward, other_advanced, perc_ident, phi_pattern, query_file, query_believe_defline, query_from, query_to, searchsp_eff, service, threshold, ungapped_alignment, word_size, short_query, alignments, alignment_view, descriptions, entrez_links_new_window, expect_low, expect_high, format_entrez_query, format_object, format_type, ncbi_gi, results_file, show_overview, megablast, template_type, template_length)\u001b[0m\n\u001b[1;32m    253\u001b[0m     delay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m    255\u001b[0m request \u001b[38;5;241m=\u001b[39m Request(url_base, message, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBiopythonClient\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m--> 256\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m results \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Can see an \"\\n\\n\" page while results are in progress,\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# if so just wait a bit longer...\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    522\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    524\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 525\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    528\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    541\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 542\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:1397\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/urllib/request.py:1357\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1355\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1357\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1358\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error Tunnel connection failed: 503 Service Unavailable>"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print('** PSI-BLAST in progress.... **')\n",
    "start_time = time.time()\n",
    "psiblast(751, \"Seq_1\", 0)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print('** PSI-BLAST process completed in {:.2f} minutes {:.2f} seconds **'.format(execution_time // 60, execution_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad961213-84f2-4464-904a-d14a27dca87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "019a46d0-6bcc-44fd-8458-a97a37486673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from Bio import SeqIO\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a0c0e-a7d3-4dc5-96c0-fa18a6a96f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission to DUET server\n",
    "# br = msp.StatefulBrowser()\n",
    "# br.session.proxies = proxies   # THIS IS THE SOLUTION!\n",
    "# for i in range(noOfMuts):\n",
    "#     br.open(url1)\n",
    "#     form = br.select_form(nr=1)\n",
    "#     form.set(\"wild\",pdbFile)\n",
    "#     br[\"mutation\"] = muts[i].strip()\n",
    "#     br[\"chain\"] = fChain\n",
    "#     res = br.submit_selected()\n",
    "#     #Fetch results from the webpage\n",
    "#     content = br.page.find('div',attrs={\"class\":\"well\"})\n",
    "#     if content:\n",
    "#         stability=content.findAll(\"font\",attrs={\"size\":\"4\"})\n",
    "#         for c in range(len(stability)):\n",
    "#             fapnd = open('outFiles/'+tools[c]+'.out', \"a\")\n",
    "#             fapnd.write(muts[i].strip()+','+stability[c].contents[1].contents[0]+','+stability[c].contents[0].lstrip().rstrip().replace(' kcal/mol (','')+'\\n')\n",
    "#             fapnd.close()\n",
    "#     elif not content:\n",
    "#         error = br.page.find(\"div\",attrs={\"class\":\"alert alert-error\"})\n",
    "#         if \"Error\" in error.text:\n",
    "#             logFile.write(error.text)\n",
    "#     else:\n",
    "#         logFile.write(br.page.text)\n",
    "# logFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "89a04cad-5e74-4217-8281-e546634c39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# response = requests.get(url)\n",
    "# soup = bs(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "358f90a3-523d-40a5-89cd-66eb66000303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fasta Seq\n",
    "inputFile = \"../../fileUpload/751/Seq_1.fasta\"\n",
    "seq_record = next(SeqIO.parse(open(inputFile),'fasta'))\n",
    "fasSeq = seq_record.seq\n",
    "\n",
    "url = \"https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastp&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome\"\n",
    "proxies = {'https':'http://proxy.ibab.ac.in:3128/', 'http':'http://proxy.ibab.ac.in:3128/'}\n",
    "session = requests.Session()\n",
    "response = session.get(url)\n",
    "soup = bs(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "d2cb2e9f-5a13-4311-8bfe-420cd5e81436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "form_data = {'QUERY': fasSeq, 'RUN_PSIBLAST': 'on', \"SELECTED_PROG_TYPE\": \"psiBlast\", \"JOB_TITLE\": \"Seq_1\", \"dbAbbr\": \"nr\", }\n",
    "response = session.post(url, data=form_data)\n",
    "# content = response.content\n",
    "# soup = bs(content,\"lxml\")\n",
    "# print(soup.find(\"input\", id_=\"dbAbbr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "260b6b30-7812-4752-a507-78a5205a0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = response.content\n",
    "# soup = bs(content,\"lxml\")\n",
    "# soup.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "3d4eb454-2f3c-474f-9540-b471f0e07015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<input id=\"dbAbbr\" name=\"DB_DISPLAY_NAME\" type=\"hidden\" value=\"\"/>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# content = response.content\n",
    "# content\n",
    "# abc = bs(content,\"lxml\")\n",
    "# print(soup.find(\"input\", id_=\"dbAbbr\"))\n",
    "# abc.find(\"input\", attrs={\"id\":\"dbAbbr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "88d952ac-3a18-47a7-9995-82e32594a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = response.content\n",
    "# abc = bs(content,\"lxml\")\n",
    "# abc.find('form', {'id': 'searchForm'})\n",
    "# print(soup.find(\"p\", class_=\"WAITING\"))\n",
    "# tagPl = \"<p class='WAITING'>This page will be automatically updated in <b>17</b> seconds</p>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "b008fc64-8dec-4f78-b459-d9f896571efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputFile = \"/home/software/Test_DUF/One_Seq/DUF3255/PF11631.fasta\"\n",
    "seq_record = next(SeqIO.parse(open(inputFile),'fasta'))\n",
    "fasSeq = seq_record.seq\n",
    "len(fasSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9cb36-222b-471f-97a7-71c6e891d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "def psiblast_out_process(dufID, pfamID, c):\n",
    "    psiblast_output_file = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_psiblast.out\"\n",
    "    allTitlesFile = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_all_titles.txt\"\n",
    "    wordDictFile = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_word_dict.txt\"\n",
    "    delListFile = f\"fileUpload/{dufID}/{pfamID}_Split_{c}_del_list.txt\"\n",
    "    if int(c) == 0:\n",
    "        psiblast_output_file = f\"fileUpload/{dufID}/{pfamID}_psiblast.out\"\n",
    "        allTitlesFile = f\"fileUpload/{dufID}/{pfamID}_all_titles.txt\"\n",
    "        wordDictFile = f\"fileUpload/{dufID}/{pfamID}_word_dict.txt\"\n",
    "        delListFile = f\"fileUpload/{dufID}/{pfamID}_del_list.txt\"\n",
    "        \n",
    "    # Function to count total occurrences of word in entire file\n",
    "    def word_count(input_word, word_dict):\n",
    "        for words in input_word:\n",
    "            if words != '':\n",
    "                if words.lower() in word_dict:\n",
    "                    word_dict[words.lower()] += 1\n",
    "                else:\n",
    "                    word_dict[words.lower()] = 1\n",
    "    \n",
    "    cnt1 = 0\n",
    "    cnt2 = 0\n",
    "\n",
    "    # deleting empty lines, if any in the psiblast output file\n",
    "    cmd = f\"sed -i '/^$/d' {psiblast_output_file}\"\n",
    "    os.system(cmd)\n",
    "\n",
    "    # counting number of lines in psiblast output....to check if no hits obtained (empty file)\n",
    "    blast_cnt = os.popen(f\"wc -l < {psiblast_output_file}\").read()\n",
    "\n",
    "    if int(blast_cnt.rstrip()) > 1:\n",
    "        lastLine = f\"sed '${{/Search has CONVERGED!/d;}}' {psiblast_output_file} > temFile.txt && mv temFile.txt {psiblast_output_file}\"\n",
    "        os.system(lastLine)\n",
    "        psibRst = pd.read_csv(psiblast_output_file, header=None)\n",
    "        try:\n",
    "            titles = open(allTitlesFile, 'w')           \n",
    "            for i in range(1, len(psibRst)):\n",
    "                if float(psibRst[1][i]) >= 80 and float(psibRst[2][i]) >= 20:\n",
    "                    cnt1 += 1\n",
    "                    target_cov = float(psibRst[3][i]) / float(psibRst[4][i]) * 100\n",
    "                    if 80 <= target_cov <= 120:\n",
    "                        cnt2 += 1\n",
    "                        x = psibRst[0][i].split(sep=\"[\")[0].strip()\n",
    "                        titles.write(x+\"\\n\")\n",
    "            titles.close()\n",
    "        except Exception as e:\n",
    "            status = \"Error while retrieving hits titles\"\n",
    "\n",
    "        if cnt1 == 0:\n",
    "            status = \"No significant hits found with query coverage greater than 80% and % identity greater than 20%\"\n",
    "\n",
    "        elif cnt1 != 0 and cnt2 == 0:\n",
    "            status = \"No hits fulfill target coverage 80-120%, although query coverage and percent identity criteria is fulfilled\"\n",
    "\n",
    "        else:\n",
    "            # print(\"**Creating word dictionary**\")\n",
    "            file_path = allTitlesFile\n",
    "\n",
    "            # Creating word dictionary\n",
    "            word_dict = collections.OrderedDict()\n",
    "\n",
    "            filter_word_list = []\n",
    "            del_list = [dufID, pfamID]\n",
    "\n",
    "            chars = ['(', ')', ':', '=', ',', \"'\", ';']\n",
    "\n",
    "            # deleting unwanted characters from titles file\n",
    "            for i in chars:\n",
    "                cmd = f'sed -i \"s/{i}//gI\" {allTitlesFile}'\n",
    "                os.system(cmd)\n",
    "\n",
    "            # store count of words\n",
    "            with open(file_path) as hits:\n",
    "                for line in hits:\n",
    "                    word_count(line.strip().split(' '), word_dict)\n",
    "\n",
    "            word_list = list(word_dict.items())\n",
    "\n",
    "            # list of common words to be eliminated during filtration for putative hits\n",
    "            common_word_list = ['DUF', 'domain-containing', 'uncharacterized', 'uncharacterised', 'multispecies',\n",
    "                                'wiith', 'to', 'of', 'in', 'similar', 'from', 'plasmid', '(plasmid)', 'contains',\n",
    "                                'containing', 'partial', 'unknown', 'unnamed', 'hypothetical','RecName FullUncharacterized',\n",
    "                                'RecName Full Uncharacterize', 'PREDICTED', 'LOW QUALITY PROTEIN']\n",
    "\n",
    "            # filtering word list based eliminating low occurrences\n",
    "            for i in word_list:\n",
    "                occ = os.popen(f'grep -i -c \"{i[0]}\" {allTitlesFile}').read()\n",
    "                if occ != '' and int(occ) > 5:\n",
    "                    filter_word_list += [i]\n",
    "                else:\n",
    "                    del_list = del_list + [i[0]]\n",
    "\n",
    "            # filtering word list by eliminating words in common word list\n",
    "            for x in common_word_list:\n",
    "                filter_word_list = [i for i in filter_word_list if not i[0].lower().startswith(x.lower())]\n",
    "                del_list = del_list + [x]\n",
    "\n",
    "            # filtering word list by eliminating words which are combination of letters and numbers\n",
    "\n",
    "            filter_word_list = [i for i in filter_word_list if\n",
    "                                not re.search(r'\\d', i[0]) is not None and re.search(r'[a-zA-Z]', i[0]) is not None]\n",
    "            del_list = del_list + [i[0] for i in filter_word_list if\n",
    "                                   re.search(r'\\d', i[0]) is not None and re.search(r'[a-zA-Z]', i[0]) is not None]\n",
    "\n",
    "            # writing filtered word dict to file:\n",
    "            with open(wordDictFile, \"w\") as f:\n",
    "                for kv in filter_word_list:\n",
    "                    f.write(str(kv) + '\\n')\n",
    "            f.close()\n",
    "\n",
    "            # writing deleted words to file:\n",
    "            with open(delListFile, \"w\") as f:\n",
    "                for word in del_list:\n",
    "                    f.write(str(word) + '\\n')\n",
    "            f.close()\n",
    "\n",
    "            status = \"Word dictionary created using retrieved blast hit titles\"\n",
    "\n",
    "            if len(filter_word_list) == 0:\n",
    "                status = \"Hits with qcov > 80% and pident > 20% are insignificant\"\n",
    "    else:\n",
    "        status = \"No hits obtained in psiblast run\"\n",
    "\n",
    "    return status\n",
    "\n",
    "# duf = sys.argv[1]\n",
    "# pf = sys.argv[2]\n",
    "# count = sys.argv[3]\n",
    "# psiblast_out_process(duf, pf, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
